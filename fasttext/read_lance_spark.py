#!/usr/bin/env python3
"""
ä½¿ç”¨Spark Lanceè¿æ¥å™¨è¯»å–Lanceæ–‡ä»¶
åŸºäºæä¾›çš„Sparkä»£ç æ”¹å†™çš„æœ¬åœ°ç‰ˆæœ¬
"""

import os
import sys
from pathlib import Path

def read_lance_with_spark(lance_file_path):
    """ä½¿ç”¨Spark Lanceè¿æ¥å™¨è¯»å–Lanceæ–‡ä»¶"""
    try:
        from pyspark.sql import SparkSession
        from pyspark.sql.functions import lit
        
        print("=== ä½¿ç”¨Spark Lanceè¿æ¥å™¨è¯»å– ===")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(lance_file_path):
            print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {lance_file_path}")
            return None
        
        # åˆ›å»ºSparkä¼šè¯ï¼ˆé…ç½®JARè·¯å¾„ï¼‰
        print("åˆ›å»ºSparkä¼šè¯...")
        jar_path = "/data/code/spark-jars/delta-core_2.12-2.4.0.jar"
        spark = SparkSession.builder \
            .appName('read_lance_local') \
            .config("spark.jars", jar_path) \
            .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
            .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
            .config("spark.sql.caseSensitive", "true") \
            .getOrCreate()
        
        print("Sparkä¼šè¯åˆ›å»ºæˆåŠŸ")
        
        # ä½¿ç”¨Lanceæ ¼å¼è¯»å–æ–‡ä»¶
        print(f"è¯»å–Lanceæ–‡ä»¶: {lance_file_path}")
        
        # å°†è·¯å¾„è½¬æ¢ä¸ºfile://æ ¼å¼
        file_uri = f"file://{os.path.abspath(lance_file_path)}"
        print(f"æ–‡ä»¶URI: {file_uri}")
        
        # ç”±äºæ²¡æœ‰Lance Sparkè¿æ¥å™¨ï¼Œæˆ‘ä»¬å…ˆå°è¯•è¯»å–ä¸ºparquetæ ¼å¼
        # å¦‚æœå¤±è´¥ï¼Œåˆ™å›é€€åˆ°æœ¬åœ°lanceåº“
        try:
            df = spark.read.parquet(file_uri)
        except Exception as e:
            print(f"Sparkè¯»å–å¤±è´¥: {e}")
            print("å›é€€åˆ°æœ¬åœ°Lanceåº“...")
            raise Exception("éœ€è¦ä½¿ç”¨æœ¬åœ°Lanceåº“")
        
        # æ·»åŠ è¡ŒIDå’Œå…¶ä»–ä¿¡æ¯
        df_with_metadata = df.select('*', '_rowid').withColumn('lance_dataset', lit(os.path.basename(lance_file_path)))
        
        print("âœ“ Lanceæ–‡ä»¶è¯»å–æˆåŠŸ!")
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        print("\n=== æ•°æ®é›†ä¿¡æ¯ ===")
        row_count = df_with_metadata.count()
        print(f"æ€»è¡Œæ•°: {row_count:,}")
        
        # è·å–schema
        print(f"\nSchema:")
        df_with_metadata.printSchema()
        
        # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
        print("\n=== å‰5è¡Œæ•°æ® ===")
        df_with_metadata.show(5, truncate=False)
        
        # è·å–åˆ—ç»Ÿè®¡ä¿¡æ¯
        print("\n=== åˆ—ç»Ÿè®¡ä¿¡æ¯ ===")
        columns = df_with_metadata.columns
        for col in columns[:10]:  # åªæ˜¾ç¤ºå‰10åˆ—
            try:
                non_null_count = df_with_metadata.filter(df_with_metadata[col].isNotNull()).count()
                print(f"{col}: éç©ºå€¼ {non_null_count:,}/{row_count:,}")
            except Exception as e:
                print(f"{col}: ç»Ÿè®¡å¤±è´¥ - {e}")
        
        # è½¬æ¢ä¸ºPandas DataFrameï¼ˆå°å¿ƒå†…å­˜ï¼‰
        if row_count <= 10000:  # åªæœ‰åœ¨æ•°æ®é‡ä¸å¤§æ—¶æ‰è½¬æ¢
            print(f"\n=== è½¬æ¢ä¸ºPandas DataFrame ===")
            try:
                pandas_df = df_with_metadata.limit(1000).toPandas()
                print(f"Pandas DataFrameå½¢çŠ¶: {pandas_df.shape}")
                
                # ä¿å­˜æ ·æœ¬æ•°æ®
                import json
                sample_file = "/data/code/Oprover/fasttext/lance_spark_sample.json"
                try:
                    sample_data = pandas_df.head(5).to_dict('records')
                    with open(sample_file, 'w', encoding='utf-8') as f:
                        json.dump(sample_data, f, ensure_ascii=False, indent=2, default=str)
                    print(f"âœ“ æ ·æœ¬æ•°æ®å·²ä¿å­˜åˆ°: {sample_file}")
                except Exception as e:
                    print(f"âœ— ä¿å­˜æ ·æœ¬æ•°æ®å¤±è´¥: {e}")
                    
                return pandas_df
                
            except Exception as e:
                print(f"è½¬æ¢ä¸ºPandaså¤±è´¥: {e}")
        else:
            print(f"æ•°æ®é‡è¾ƒå¤§({row_count:,}è¡Œ)ï¼Œè·³è¿‡Pandasè½¬æ¢")
        
        # åœæ­¢Sparkä¼šè¯
        spark.stop()
        return df_with_metadata
        
    except ImportError as e:
        print(f"âœ— PySparkæœªå®‰è£…: {e}")
        print("è¯·å®‰è£…PySpark: pip install pyspark")
        return None
    except Exception as e:
        print(f"âœ— Sparkè¯»å–å¤±è´¥: {e}")
        return None

def read_lance_with_local_tools():
    """ä½¿ç”¨æœ¬åœ°å·¥å…·å°è¯•è¯»å–"""
    print("\n=== æœ¬åœ°å·¥å…·è¯»å–å°è¯• ===")
    
    lance_file_path = "/data/code/Oprover/data/github_raw/00cef695-b55c-4c85-bb00-f49683c88582.lance"
    
    # å°è¯•1: ä½¿ç”¨lanceåº“
    print("1. å°è¯•ä½¿ç”¨lanceåº“...")
    try:
        import lance
        dataset = lance.dataset(lance_file_path)
        print("âœ“ Lanceåº“è¯»å–æˆåŠŸ!")
        
        schema = dataset.schema
        print(f"Schema: {schema}")
        
        count = dataset.count_rows()
        print(f"è¡Œæ•°: {count:,}")
        
        # è¯»å–æ•°æ®
        table = dataset.to_table()
        df = table.to_pandas()
        
        print(f"DataFrameå½¢çŠ¶: {df.shape}")
        print(f"åˆ—: {list(df.columns)}")
        
        return df
        
    except Exception as e:
        print(f"âœ— Lanceåº“å¤±è´¥: {e}")
    
    # å°è¯•2: ä½¿ç”¨lancedb
    print("\n2. å°è¯•ä½¿ç”¨lancedb...")
    try:
        import lancedb
        
        parent_dir = os.path.dirname(lance_file_path)
        db = lancedb.connect(parent_dir)
        
        tables = db.table_names()
        print(f"å¯ç”¨è¡¨: {tables}")
        
        if tables:
            table_name = tables[0]
            print(f"è¯»å–è¡¨: {table_name}")
            
            # å°è¯•ä¸åŒçš„è®¿é—®æ–¹å¼
            try:
                table = db[table_name]
                df = table.limit(1000).to_pandas()
                print(f"âœ“ LanceDBè¯»å–æˆåŠŸ! å½¢çŠ¶: {df.shape}")
                return df
            except Exception as e:
                print(f"âœ— LanceDBè¡¨è®¿é—®å¤±è´¥: {e}")
        
    except Exception as e:
        print(f"âœ— LanceDBå¤±è´¥: {e}")
    
    return None

def analyze_file_structure():
    """åˆ†æLanceæ–‡ä»¶ç»“æ„"""
    lance_file_path = "/data/code/Oprover/data/github_raw/00cef695-b55c-4c85-bb00-f49683c88582.lance"
    
    print("\n=== Lanceæ–‡ä»¶ç»“æ„åˆ†æ ===")
    
    if not os.path.exists(lance_file_path):
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {lance_file_path}")
        return
    
    file_size = os.path.getsize(lance_file_path)
    print(f"æ–‡ä»¶å¤§å°: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•
    parent_dir = os.path.dirname(lance_file_path)
    print(f"çˆ¶ç›®å½•: {parent_dir}")
    
    # åˆ—å‡ºç›®å½•å†…å®¹
    try:
        items = os.listdir(parent_dir)
        print(f"ç›®å½•å†…å®¹: {items}")
    except Exception as e:
        print(f"æ— æ³•åˆ—å‡ºç›®å½•å†…å®¹: {e}")
    
    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    with open(lance_file_path, 'rb') as f:
        header = f.read(100)
        f.seek(-100, 2)
        footer = f.read(100)
    
    print(f"æ–‡ä»¶å¤´éƒ¨: {header[:50].hex()}")
    print(f"æ–‡ä»¶å°¾éƒ¨: {footer[-50:].hex()}")
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«Lanceæ ‡è¯†
    if b'LANC' in footer:
        print("âœ“ ç¡®è®¤Lanceæ ¼å¼æ–‡ä»¶")
    else:
        print("âœ— æœªå‘ç°Lanceæ ¼å¼æ ‡è¯†")

def main():
    """ä¸»å‡½æ•°"""
    lance_file_path = "/data/code/Oprover/data/github_raw/00cef695-b55c-4c85-bb00-f49683c88582.lance"
    
    print("Lanceæ–‡ä»¶è¯»å–å·¥å…·")
    print("="*50)
    
    # åˆ†ææ–‡ä»¶ç»“æ„
    analyze_file_structure()
    
    # æ–¹æ³•1: ä½¿ç”¨Spark Lanceè¿æ¥å™¨
    result = read_lance_with_spark(lance_file_path)
    
    if result is not None:
        print("\nâœ… Sparkæ–¹æ³•æˆåŠŸ!")
        return result
    
    # æ–¹æ³•2: ä½¿ç”¨æœ¬åœ°å·¥å…·
    print("\n" + "="*50)
    print("Sparkæ–¹æ³•å¤±è´¥ï¼Œå°è¯•æœ¬åœ°å·¥å…·...")
    
    result = read_lance_with_local_tools()
    
    if result is not None:
        print("\nâœ… æœ¬åœ°å·¥å…·æˆåŠŸ!")
        return result
    
    print("\nâŒ æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†")
    print("\nğŸ’¡ å»ºè®®:")
    print("1. å®‰è£…PySparkå’ŒLance Sparkè¿æ¥å™¨")
    print("2. é…ç½®æ­£ç¡®çš„Sparkç¯å¢ƒ")
    print("3. ä½¿ç”¨åŸå§‹çš„Sparké›†ç¾¤ç¯å¢ƒè¯»å–")
    
    return None

if __name__ == "__main__":
    result = main()
