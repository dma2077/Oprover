import os
import json
import time
import argparse
import pandas as pd
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from pathlib import Path

from model import APIModel, default_model
from dataset import DifficultyDataset


class DifficultyInference:
    """éš¾åº¦è¯„ä¼°æ¨ç†å¼•æ“ï¼Œè´Ÿè´£è¯»å–æ•°æ®ã€è°ƒç”¨æ¨¡å‹ã€ä¿å­˜ç»“æœ"""
    
    def __init__(self, model: Optional[APIModel] = None, dataset: Optional[DifficultyDataset] = None):
        """
        åˆå§‹åŒ–æ¨ç†å¼•æ“
        
        Args:
            model: APIæ¨¡å‹
            dataset: æ•°æ®é›†å¤„ç†å™¨
        """
        self.model = model or default_model
        self.dataset = dataset or DifficultyDataset()
    
    def process_single_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªæ•°æ®é¡¹
        
        Args:
            item: æ•°æ®é¡¹ï¼ŒåŒ…å«uuidå’Œformal_statement
            
        Returns:
            å¤„ç†åçš„æ•°æ®é¡¹
        """
        uuid = item.get("uuid")
        formal_statement = item.get("formal_statement", "").strip()
        
        if not formal_statement:
            return {
                "uuid": uuid,
                "formal_statement": formal_statement,
                "model_output": None,
                "difficulty_score": None,
                "success": False,
                "error": "Empty formal statement"
            }
        
        try:
            # æ„å»ºæç¤º
            prompt = self.dataset.build_prompt(formal_statement)
            
            # è°ƒç”¨æ¨¡å‹é¢„æµ‹
            prediction = self.model.predict(
                prompt=prompt,
                expected_keys=self.dataset.get_expected_keys(),
                validate_fn=self.dataset.get_validation_function()
            )
            
            if prediction.get("status") == "success" and prediction.get("data"):
                data = prediction["data"]
                difficulty_score = data.get("Difficulty")
                
                return {
                    "uuid": uuid,
                    "formal_statement": formal_statement,
                    "model_output": prediction.get("response"),
                    "difficulty_score": difficulty_score,
                    "success": True,
                    "error": None
                }
            else:
                return {
                    "uuid": uuid,
                    "formal_statement": formal_statement,
                    "model_output": prediction.get("response"),
                    "difficulty_score": None,
                    "success": False,
                    "error": prediction.get("error", "Prediction failed")
                }
                
        except Exception as e:
            return {
                "uuid": uuid,
                "formal_statement": formal_statement,
                "model_output": None,
                "difficulty_score": None,
                "success": False,
                "error": str(e)
            }
    
    def process_batch(self, batch: List[Dict[str, Any]], max_workers: int = 8) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡å¤„ç†æ•°æ®
        
        Args:
            batch: æ•°æ®æ‰¹æ¬¡
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
            
        Returns:
            å¤„ç†åçš„æ•°æ®æ‰¹æ¬¡
        """
        results = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(self.process_single_item, item): item for item in batch}
            
            for future in tqdm(as_completed(futures), total=len(futures), desc="Processing batch"):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    print(f"Error processing item: {e}")
                    # ä¿ç•™åŸå§‹æ•°æ®é¡¹
                    original_item = futures[future]
                    results.append({
                        "uuid": original_item.get("uuid"),
                        "formal_statement": original_item.get("formal_statement"),
                        "model_output": None,
                        "difficulty_score": None,
                        "success": False,
                        "error": str(e)
                    })
        
        return results
    
    def create_batch(self, data: List[Dict[str, Any]], batch_size: int = 1) -> List[List[Dict[str, Any]]]:
        """
        åˆ›å»ºæ‰¹æ¬¡æ•°æ®
        
        Args:
            data: åŸå§‹æ•°æ®
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            æ‰¹æ¬¡æ•°æ®åˆ—è¡¨
        """
        batches = []
        for i in range(0, len(data), batch_size):
            batch = data[i:i + batch_size]
            batches.append(batch)
        return batches


def main():
    """ä¸»å‡½æ•°ï¼Œå¤„ç†å‘½ä»¤è¡Œå‚æ•°å¹¶æ‰§è¡Œæ¨ç†ä»»åŠ¡"""
    parser = argparse.ArgumentParser(description="éš¾åº¦è¯„ä¼°æ¨ç†å¼•æ“")
    parser.add_argument("--input", type=str, required=True, 
                       help="è¾“å…¥parquetæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", type=str, default="results.jsonl", 
                       help="è¾“å‡ºJSONLæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--workers", type=int, default=8, 
                       help="æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°")
    parser.add_argument("--batch-size", type=int, default=100, 
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--max-items", type=int, default=None, 
                       help="æœ€å¤§å¤„ç†é¡¹ç›®æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¨ç†å¼•æ“
    dataset = DifficultyDataset()
    inference = DifficultyInference(dataset=dataset)
    
    print(f"ğŸš€ å¯åŠ¨éš¾åº¦è¯„ä¼°æ¨ç†å¼•æ“")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"ğŸ”§ å·¥ä½œçº¿ç¨‹: {args.workers}")
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    
    try:
        # è¯»å–parquetæ–‡ä»¶
        print(f"\nğŸ“Š è¯»å–æ•°æ®æ–‡ä»¶...")
        df = pd.read_parquet(args.input)
        print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡æ•°æ®")
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—
        required_columns = ["uuid", "formal_statement"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            print(f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
            print(f"ğŸ“‹ å¯ç”¨åˆ—: {list(df.columns)}")
            return 1
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data = []
        for _, row in df.iterrows():
            data.append({
                "uuid": row["uuid"],
                "formal_statement": row["formal_statement"]
            })
        
        # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        if args.max_items:
            data = data[:args.max_items]
            print(f"ğŸ”§ é™åˆ¶å¤„ç†æ•°é‡ä¸º: {len(data)} æ¡")
        
        print(f"ğŸ“Š å‡†å¤‡å¤„ç† {len(data)} æ¡æ•°æ®")
        
        # åˆ›å»ºæ‰¹æ¬¡
        batches = inference.create_batch(data, args.batch_size)
        print(f"ğŸ“¦ åˆ†ä¸º {len(batches)} ä¸ªæ‰¹æ¬¡å¤„ç†")
        
        # å¤„ç†æ‰€æœ‰æ‰¹æ¬¡
        processed_count = 0
        success_count = 0
        
        # åˆ›å»ºæˆ–æ¸…ç©ºè¾“å‡ºæ–‡ä»¶
        print(f"\nğŸ’¾ åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶: {args.output}")
        with open(args.output, 'w', encoding='utf-8') as f:
            pass  # åˆ›å»ºç©ºæ–‡ä»¶
        
        for i, batch in enumerate(batches):
            print(f"\nğŸ” å¤„ç†æ‰¹æ¬¡ {i+1}/{len(batches)} ({len(batch)} æ¡æ•°æ®)")
            
            # å¤„ç†æ‰¹æ¬¡
            results = inference.process_batch(batch, args.workers)
            
            # ç«‹å³ä¿å­˜æ‰¹æ¬¡ç»“æœ
            print(f"ğŸ’¾ ä¿å­˜æ‰¹æ¬¡ {i+1} ç»“æœ...")
            with open(args.output, 'a', encoding='utf-8') as f:
                for result in results:
                    f.write(json.dumps(result, ensure_ascii=False) + "\n")
            
            # ç»Ÿè®¡
            processed_count += len(results)
            batch_success = len([r for r in results if r["success"]])
            success_count += batch_success
            
            print(f"âœ… æ‰¹æ¬¡ {i+1} å®Œæˆ: å¤„ç† {len(results)} æ¡ï¼ŒæˆåŠŸ {batch_success} æ¡ï¼Œå·²ä¿å­˜")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            time.sleep(1)
        
        # æœ€ç»ˆç»Ÿè®¡
        stats = {
            "status": "completed",
            "total": len(data),
            "processed": processed_count,
            "success": success_count,
            "success_rate": success_count / processed_count if processed_count > 0 else 0
        }
        
        print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆ!")
        print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯: {stats}")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
        
    except Exception as e:
        print(f"\nâŒ ä»»åŠ¡å¤±è´¥: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
